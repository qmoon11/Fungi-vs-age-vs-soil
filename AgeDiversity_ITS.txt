
########################################################################################################
Step 1: Check Primers
########################################################################################################
#Check if primers are present in a sequencing file. Lets check for the forward primer in both the R1 and R2 reads
grep -c --color GTGAATCATCGAATCTTTGAA *.fastq.gz

#let check reverse primer just in case
grep -c --color TCCTCCGCTTATTGATATGC *.fastq.gz

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
RESULTS: 
- No primers found, must have been removed by the core
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++




########################################################################################################
Step 2: Import to QIIME
########################################################################################################
#activate QIIME2 conda environment. To set up QIIME2 environement on cluster, see https://docs.qiime2.org/2024.10/install/native/
conda activate qiime2-amplicon-2024.10


----------------------------
#IMPORT DEMULTIPLEXED DATA
----------------------------

qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path AgeDiversityManifest_ITS.tsv \
  --input-format PairedEndFastqManifestPhred33V2 \
  --output-path imported-paired-end-seqs_ITS2.qza


#CREATE a summary of demultiplexed data
qiime demux summarize \
  --i-data imported-paired-end-seqs_ITS2.qza \
  --o-visualization demux_ITS2.qzv

#Upload .qzv file to https://view.qiime2.org/

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
RESULTS: 
- For both forward and reverse primers. Have identical numbers, which makes sense
-Total reads: 1652282, mean: 17577.468085, median: 961.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



########################################################################################################
Step 3: Denoise DADA2
########################################################################################################

----------------------------
#Denoise DADA2
----------------------------
#reminder: forward is left and reverse is right
#I am choosing to run DADA2 in QIIME2 becuase I like the combined plots of PHRED score by base position
#I am choosing these trunc parameters as they are where the median Phred score dips below 30 (for a sustained period)

 qiime dada2 denoise-paired \
  --i-demultiplexed-seqs imported-paired-end-seqs_ITS2.qza \
  --p-trim-left-f 3 \
  --p-trunc-len-f 210 \
  --p-trim-left-r 7 \
  --p-trunc-len-r 170 \
  --o-representative-sequences rep-seqs_ITS2.qza \
  --o-table table_ITS2.qza \
  --o-denoising-stats denoising-stats_ITS2.qza \
  --p-n-threads 0 

  qiime metadata tabulate \
  --m-input-file denoising-stats_ITS2.qza\
  --o-visualization dada2-stats-summ_ITS2.qzv
 


  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
RESULTS: 
- 94 samples sequenced
- Tried many parameters and these work best. In total about 70% of data ends up kept and merged. 
-these parameters keep about 60-75% of reads through filtering, merge, and chimera check.
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++







########################################################################################################
Step 4: Cluster OTU with Vsearch
########################################################################################################

#CLUSTER OTUs by using vsearch de novo
qiime vsearch cluster-features-de-novo \
  --i-table table_ITS2.qza  \
  --i-sequences rep-seqs_ITS2.qza \
  --p-perc-identity 0.98 \
  --o-clustered-table table-clustered_ITS2.qza \
  --o-clustered-sequences rep-seqs-clustered_ITS2.qza



########################################################################################################
Step 5: Export rep-seqs, OTU table
########################################################################################################
#write out OTU Table
qiime tools export \
--input-path table-clustered_ITS2.qza \
--output-path OTU_table

#convert from QIIME format to TSV
biom convert -i OTU_table/feature-table.biom \
-o OTU_table/ITS2_OTU_table.tsv --to-tsv

#write out rep seqs of OTUs, final format is .fasta
qiime tools export \
--input-path rep-seqs-clustered_ITS2.qza \
--output-path rep-seqs

########################################################################################################
Step 6: Run MUMU
########################################################################################################

#################################################################################
Run MUMU
https://github.com/frederic-mahe/mumu
#################################################################################
conda deactivate

#download and set up MUMU
git clone https://github.com/frederic-mahe/mumu.git
cd ./mumu/
module load gcc/15.1.0 #Load a newer GCC module
make
make check
mkdir -p ~/bin
make install PREFIX=$HOME
make install  # as root or sudo
ls $HOME/bin/mumu

#Build tab-separated, OTU pairwise similarity scores (required)
conda activate qiime2-amplicon-2024.10
vsearch --allpairs_global rep-seqs/dna-sequences.fasta --blast6out similarities.tsv --id 0.0


#convert to mumu format 
awk '{printf "%s\t%s\t%.4f\n",$1,$2,$3/100}' similarities.tsv > similarity_scores.tsv

#manually remove row 1 in the output otu csv as it is empty

#run mumu
mumu \
    --otu_table ../MoonITS2/OTU_table/ITS2_OTU_table.tsv \
    --match_list ../MoonITS2/similarity_scores.tsv \
    --log /dev/null \
    --new_otu_table ../MoonITS2/OTU_table/MUMU_OTU_ITS.table

#MUMU_OTU_ITS.table is the table to be used for downstream analysis

