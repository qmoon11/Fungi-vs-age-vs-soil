########################################################################################################
Pipeline to go from raw 16sV4 reads from IMR core to ASV table and rep seqs
Steps:
1) check for primers in raw data
2) load into QIIME2
2a) Denoise with DADA2
2b) Cluster 100% OTUs/ASV
2c) Export ASV table, rep seps, taxonomy. To load into R

########################################################################################################



########################################################################################################
Step 1 
########################################################################################################
#Check if primers are present in a sequencing file. Lets check for the forward primer in both the R1 and R2 reads
#here i use [ATCG] as a bash compatible version of Y and R in primer sequences
grep -c --color 'GTG[CT]CAGC[AC]GCCGCGGTAA' *.fastq.gz

#let check reverse primer just in case
grep -E -c --color 'GGACTAC[ATCG][ACG]GGGT[AT]TCTAAT' *.fastq.gz

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
RESULTS: 
- No primers found, must have been removed by the core
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


########################################################################################################
Step 2 
########################################################################################################

#activate QIIME2 conda environment. To set up QIIME2 environement on cluster, see https://docs.qiime2.org/2024.10/install/native/
conda activate qiime2-amplicon-2024.10

----------------------------
#2) IMPORT DEMULTIPLEXED DATA
----------------------------
#import sequence data to QIIME, uses manifest.tsv to locate forward and reverse reads.
#Phred33 is standard illumina quality score
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path AgeDiversityManifest-16s.tsv \
  --input-format PairedEndFastqManifestPhred33V2 \
  --output-path imported-paired-end-seqs_16s.qza

#CREATE a summary of demultiplexed data
qiime demux summarize \
  --i-data imported-paired-end-seqs_16s.qza \
  --o-visualization demux_16s.qzv

#Upload .qzv file to https://view.qiime2.org/ to visualize results

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
RESULTS: 
- 94 Samples
- For both forward and reverse primers. Have identical numbers, which makes sense
-Total reads: 6291145, mean: 66927.07 median:  75483.0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


########################################################################################################
Step 3: Denoise DADA2
########################################################################################################
#reminder: forward is left and reverse is right
#I am choosing to run DADA2 in QIIME2 becuase I like the combined plots of PHRED score by base position
#I am choosing these trunc parameters as they are where the median Phred score dips below 30 (for a sustained period)


#Lets try with and without trunc
# Truncate with adjusted chimera filtering
# I adjusted the chimera filtering to prevent most reads from being dropped
qiime dada2 denoise-paired \
  --i-demultiplexed-seqs imported-paired-end-seqs_16s.qza \
  --p-trim-left-f 5 \
  --p-trunc-len-f 258 \
  --p-trim-left-r 5 \
  --p-trunc-len-r 190 \
  --p-min-fold-parent-over-abundance 3 \
  --o-representative-sequences rep-seqs_16s_trunc.qza \
  --o-table table_16s_trunc.qza \
  --o-denoising-stats denoising-stats_16s_trunc.qza \
  --p-n-threads 0


qiime metadata tabulate \
  --m-input-file denoising-stats_16s_trunc.qza\
  --o-visualization dada2-stats-summ_16s_trunc.qzv

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
RESULTS: 
- 94 samples sequenced
- Tried many parameters and these work best. In total about 70% of data ends up kept and merged. 
-these parameters keep about 60-80% of reads through filtering, merge, and chimera check.
-note --p-min-fold-parent-over-abundance 3
- 4 pesky samples had horrible merge rates (TXO18-1, 14-03, 14-7, and HC1-36). They all have low reads ~2000 so probably just poor amplification
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


----------------------------
#2b) CLUSTER OTU using vsearch, likely not needed
----------------------------

#Here I am choosing 1.0 similarity to keep ASV
#CLUSTER OTUs by using vsearch de novo
qiime vsearch cluster-features-de-novo \
  --i-table table_16s_trunc.qza  \
  --i-sequences rep-seqs_16s_trunc.qza \
  --p-perc-identity 1.0 \
  --o-clustered-table table-clustered_1.0_16s.qza \
  --o-clustered-sequences rep-seqs-clustered_1.0_16s.qza


########################################################################################################
Step 3: Assign Taxonomy using SILVA reference
########################################################################################################

#Download SILVA 138 99% OTUs full-length sequences
wget https://data.qiime2.org/2024.10/common/silva-138-99-seqs.qza

#extract just v4 region, using primers used in the study (Walters 2015), improves assingments
qiime feature-classifier extract-reads \
  --i-sequences silva-138-99-seqs.qza \    
  --p-f-primer GTGYCAGCMGCCGCGGTAA \
  --p-r-primer GGACTACNVGGGTWTCTAAT \
  --p-min-length 100 \
  --p-max-length 400 \
  --o-reads silva-138-99-seqs-v4.qza

#Train the classifier
qiime feature-classifier fit-classifier-naive-bayes \
  --i-reference-reads silva-138-99-seqs-v4.qza \
  --i-reference-taxonomy silva-138-99-tax.qza \
  --o-classifier silva-138-99-v4-classifier.qza


#Assign taxonomy with naive bayes classifier
qiime feature-classifier classify-sklearn \
  --i-classifier silva-138-99-v4-classifier.qza \
  --i-reads rep-seqs_16s_trunc.qza \
  --o-classification taxonomy_16s.qza


########################################################################################################
Step 4: Export taxonomy, rep-seqs, and ASV table 
########################################################################################################
#export taxonmy as TSV
qiime tools export \
  --input-path taxonomy_16s.qza \
  --output-path taxonomy_export


#export rep-seqs
qiime tools export \
  --input-path rep-seqs_16s_trunc.qza \
  --output-path rep_seqs_export


#export ASV table
#convert to BIOM
qiime tools export \
  --input-path table_16s_trunc.qza \
  --output-path otu_table_export

#convert BIOM to TSV
biom convert \
  -i otu_table_export/feature-table.biom \
  -o otu_table.tsv \
  --to-tsv

#remove biom comment line
grep -v '^# Constructed from biom file' 16s_ASV_table_age.tsv > 16s_ASV_table_age_clean.tsv

########################################################################################################
Step 5: Run MUMU on rep-seqs and ASV table
https://github.com/frederic-mahe/mumu
########################################################################################################
#leave QIIME
conda deactivate

#I previously downloaded and set up MUMU (see ITS work flow)

#Lets redownload vsearch and make it executable
conda create -n myenv vsearch
conda activate myenv
conda install -c bioconda vsearch
vsearch --version

#tab-separated, OTU pairwise similarity scores (required)
vsearch \
  --usearch_global rep_seqs_export/16s_dna-sequences_age.fasta \
  --db rep_seqs_export/16s_dna-sequences_age.fasta \
  --self \
  --id 0.84 \
  --iddef 1 \
  --userfields query+target+id \
  --maxaccepts 0 \
  --query_cov 0.9 \
  --maxhits 10 \
  --userout matches_16s_age.list

#run mumu
mumu \
    --otu_table 16s_ASV_table_age.tsv \
    --match_list matches_16s_age.list \
    --log mumu_merge_16s_age.log \
    --new_otu_table new_MUMU_ASV_16s_age.table

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
RESULTS: 
- 94 samples sequenced
- MUMU found 43,351 original ASVs, after merging just 16,471
- original OTU table: ITS2_OTU_table_age.tsv
- MUMU output: new_MUMU_OTU_ITS2.table
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
